{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `dev`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import nemo\n",
    "import copy\n",
    "import tqdm\n",
    "import timeit\n",
    "import shutil\n",
    "import pathlib\n",
    "import attrdict\n",
    "import numpy as np\n",
    "\n",
    "from ruamel import yaml\n",
    "from Bio import pairwise2\n",
    "from nemo.collections import asr as nemo_asr\n",
    "from nemo.collections.asr.helpers import post_process_predictions, post_process_transcripts, word_error_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "NGC_MAP = '~/Downloads/librivox-train-all.json'\n",
    "LOCAL_MAP = [\n",
    "    '/home/stanislavv/data/nemo-librispeech/train_clean_100.json',\n",
    "    '/home/stanislavv/data/nemo-librispeech/train_clean_360.json',\n",
    "    '/home/stanislavv/data/nemo-librispeech/train_other_500.json',\n",
    "]\n",
    "AD_HOC_MAP = '/home/stanislavv/data/librispeech/train-all.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_BASE = pathlib.Path('/home/stanislavv/data/librispeech')\n",
    "\n",
    "NGC_BASE = DATA_BASE / 'ngc'\n",
    "NGC = [\n",
    "    NGC_BASE / 'librivox-dev-clean.json',\n",
    "    NGC_BASE / 'librivox-dev-other.json',\n",
    "    NGC_BASE / 'librivox-test-clean.json',\n",
    "    NGC_BASE / 'librivox-test-other.json',\n",
    "    NGC_BASE / 'librivox-train-all.json',\n",
    "]\n",
    "\n",
    "LOCAL_BASE = DATA_BASE / 'local'\n",
    "LOCAL = [\n",
    "    LOCAL_BASE / 'dev_clean.json',\n",
    "    LOCAL_BASE / 'dev_other.json',\n",
    "    LOCAL_BASE / 'test_clean.json',\n",
    "    LOCAL_BASE / 'test_other.json',\n",
    "    LOCAL_BASE / 'train_all.json',\n",
    "]\n",
    "\n",
    "NEW_LOCAL_BASE = DATA_BASE / 'new-local'\n",
    "NEW_LOCAL = [\n",
    "    NEW_LOCAL_BASE / 'dev-clean.json',\n",
    "    NEW_LOCAL_BASE / 'dev-other.json',\n",
    "    NEW_LOCAL_BASE / 'test-clean.json',\n",
    "    NEW_LOCAL_BASE / 'test-other.json',\n",
    "    NEW_LOCAL_BASE / 'train-all.json',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngc_id(audio_file):\n",
    "    return os.path.basename(audio_file)[:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap(ngc_map, local_map, new_file):\n",
    "    order = [\n",
    "        get_ngc_id(example['audio_file']) \n",
    "        for example in nemo.collections.asr.parts.manifest.item_iter(str(ngc_map))\n",
    "    ]\n",
    "    \n",
    "    local_id_index = [\n",
    "        (get_ngc_id(example['audio_file']), i)\n",
    "        for i, example in enumerate(nemo.collections.asr.parts.manifest.item_iter(str(local_map)))\n",
    "    ]\n",
    "    \n",
    "    local_id_index_dict = dict(local_id_index)\n",
    "    new_order = [local_id_index_dict[id_] for id_ in order]\n",
    "\n",
    "    lines = []\n",
    "    with open(local_map, 'r') as f:\n",
    "        lines.extend(list(f))\n",
    "    lines = [lines[id_] for id_ in new_order]\n",
    "    \n",
    "    with open(new_file, 'w') as f:\n",
    "        for line in lines:\n",
    "            f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ngc, local, new_local in zip(NGC, LOCAL, NEW_LOCAL):\n",
    "    remap(ngc, local, new_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAME = 'dev-clean'\n",
    "MAP = '/home/stanislavv/data/ljspeech/nemo/ljspeech_eval.json'\n",
    "SAMPLE_RATE = 22050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = nemo.core.NeuralModuleFactory(\n",
    "    placement=nemo.core.DeviceType.GPU,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\' \\', \\'a\\', \\'b\\', \\'c\\', \\'d\\', \\'e\\', \\'f\\', \\'g\\', \\'h\\', \\'i\\', \\'j\\', \\'k\\', \\'l\\', \\'m\\', \\'n\\', \\'o\\', \\'p\\', \\'q\\', \\'r\\', \\'s\\', \\'t\\', \\'u\\', \\'v\\', \\'w\\', \\'x\\', \\'y\\', \\'z\\', \"\\'\"]'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_CONFIG = '/home/stanislavv/src/tts/NeMo/examples/asr/configs/quartznet15x5.yaml'\n",
    "yaml_loader = yaml.YAML(typ=\"safe\")\n",
    "with open(MODEL_CONFIG) as f:\n",
    "    config = attrdict.AttrDict(yaml_loader.load(f))\n",
    "config.sample_rate = SAMPLE_RATE\n",
    "labels = list(config.labels)\n",
    "str(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttrDict({'dither': 0.0, 'features': 80, 'frame_splicing': 1, 'highfreq': 8000, 'log': True, 'log_zero_guard_type': 'clamp', 'log_zero_guard_value': 1e-05, 'lowfreq': 0, 'mag_power': 1.0, 'n_fft': 1024, 'n_window_size': 1024, 'n_window_stride': 256, 'normalize': None, 'pad_to': 16, 'pad_value': -11.52, 'preemph': None, 'sample_rate': 24000, 'stft_conv': True, 'window': 'hann', 'window_size': None, 'window_stride': None})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_CONFIG = '/home/stanislavv/src/tts/NeMo/examples/tts/configs/fasterspeech.yaml'\n",
    "yaml_loader = yaml.YAML(typ=\"safe\")\n",
    "with open(MODEL_CONFIG) as f:\n",
    "    pp_config = attrdict.AttrDict(yaml_loader.load(f))\n",
    "pp_config.sample_rate = SAMPLE_RATE\n",
    "pp_config.AudioToMelSpectrogramPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dl_params = copy.deepcopy(config.AudioToTextDataLayer)\n",
    "eval_dl_params.update(config.AudioToTextDataLayer[\"eval\"])\n",
    "del eval_dl_params[\"train\"]\n",
    "del eval_dl_params[\"eval\"]\n",
    "eval_dl_params['shuffle'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttrDict({'window_size': None, 'window_stride': None, 'n_window_size': 512, 'n_window_stride': 256, 'window': 'hann', 'normalize': 'per_feature', 'n_fft': 512, 'preemph': None, 'features': 64, 'lowfreq': 0, 'highfreq': None, 'log': True, 'log_zero_guard_type': 'clamp', 'log_zero_guard_value': 1e-05, 'dither': 0.0, 'pad_to': 16, 'frame_splicing': 1, 'stft_conv': True, 'pad_value': -11.52, 'mag_power': 2.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_CONFIG = '/home/stanislavv/src/tts/NeMo/examples/asr/configs/quartznet15x5-libritts-durs.yaml'\n",
    "yaml_loader = yaml.YAML(typ='safe')\n",
    "with open(MODEL_CONFIG) as f:\n",
    "    config = attrdict.AttrDict(yaml_loader.load(f))\n",
    "\n",
    "config.sample_rate = SAMPLE_RATE\n",
    "config.AudioToMelSpectrogramPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-04-16 07:40:33 collections:144] Dataset loaded with 64 files totalling 0.12 hours\n",
      "[NeMo I 2020-04-16 07:40:33 collections:145] 0 files were filtered totalling 0.00 hours\n"
     ]
    }
   ],
   "source": [
    "data_layer = nemo_asr.AudioToTextDataLayer(\n",
    "    manifest_filepath=MAP,\n",
    "    sample_rate=config.sample_rate,\n",
    "    labels=config.labels,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 220061]), torch.Size([64]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, al, t, tl = next(iter(data_layer._dataloader))\n",
    "a.shape, al.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42,\n",
       "       43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59,\n",
       "       61, 62])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(t.numpy().flatten())  # No big letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-04-16 07:40:38 features:144] PADDING: 16\n",
      "[NeMo I 2020-04-16 07:40:38 features:152] STFT using conv\n"
     ]
    }
   ],
   "source": [
    "data_preprocessor = nemo_asr.AudioToMelSpectrogramPreprocessor(\n",
    "    sample_rate=config.sample_rate, **config.AudioToMelSpectrogramPreprocessor\n",
    ")\n",
    "jasper_encoder = nemo_asr.JasperEncoder(\n",
    "    feat_in=config.AudioToMelSpectrogramPreprocessor[\"features\"], **config.JasperEncoder\n",
    ")\n",
    "jasper_decoder = nemo_asr.JasperDecoderForCTC(\n",
    "    feat_in=config.JasperEncoder[\"jasper\"][-1][\"filters\"], num_classes=len(config.labels)\n",
    ")\n",
    "greedy_decoder = nemo_asr.GreedyCTCDecoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_signal_e1, a_sig_length_e1, transcript_e1, transcript_len_e1 = data_layer()\n",
    "processed_signal_e1, p_length_e1 = data_preprocessor(input_signal=audio_signal_e1, length=a_sig_length_e1)\n",
    "encoded_e1, encoded_len_e1 = jasper_encoder(audio_signal=processed_signal_e1, length=p_length_e1)\n",
    "log_probs_e1 = jasper_decoder(encoder_output=encoded_e1)\n",
    "predictions_e1 = greedy_decoder(log_probs=log_probs_e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-04-16 07:40:41 actions:1468] Restoring JasperEncoder from /home/stanislavv/data/checkpoints/nemo-qn15x5-libritts_tts-config_300epochs/JasperEncoder-STEP-410400.pt\n",
      "[NeMo I 2020-04-16 07:40:41 actions:1468] Restoring JasperDecoderForCTC from /home/stanislavv/data/checkpoints/nemo-qn15x5-libritts_tts-config_300epochs/JasperDecoderForCTC-STEP-410400.pt\n",
      "[NeMo I 2020-04-16 07:40:41 actions:738] Evaluating batch 0 out of 1\n"
     ]
    }
   ],
   "source": [
    "eval_tensors = [log_probs_e1, predictions_e1, transcript_e1, transcript_len_e1, encoded_len_e1, p_length_e1]\n",
    "load_dir = '/home/stanislavv/data/checkpoints/nemo-qn15x5-libritts_tts-config_300epochs'\n",
    "evaluated_tensors = runner.infer(tensors=eval_tensors, checkpoint_dir=load_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12465878070973613"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references = post_process_transcripts(evaluated_tensors[2], evaluated_tensors[3], config.labels)\n",
    "greedy_hypotheses = post_process_predictions(evaluated_tensors[1], config.labels)\n",
    "word_error_rate(greedy_hypotheses, references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  A B C D E F G H I J K L M N O P Q R S T U V W X Y Z a b c d e f g h i j k l m n o p q r s t u v w x y z , . ! ? ; : - / \" ' ( ) [ ] { }\n"
     ]
    }
   ],
   "source": [
    "labels = list(config.labels)\n",
    "print(*labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = evaluated_tensors[2][0]\n",
    "text_len = evaluated_tensors[3][0]\n",
    "ctc_tokens = evaluated_tensors[1][0]\n",
    "ctc_logprobs = evaluated_tensors[0][0]\n",
    "ctc_len = evaluated_tensors[4][0]\n",
    "mel_len = evaluated_tensors[-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = text[0].numpy()\n",
    "text_len1 = text_len[0].numpy().item()\n",
    "ctc_tokens1 = ctc_tokens[0].numpy()\n",
    "ctc_logprobs1 = ctc_logprobs[0].numpy()\n",
    "ctc_len1 = ctc_len[0].numpy().item()\n",
    "mel_len1 = mel_len[0].numpy().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57, 476, (476, 70))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = list(text1[:text_len1])\n",
    "ctc_tokens1 = list(ctc_tokens1[:ctc_len1])\n",
    "ctc_logprobs1 = ctc_logprobs1[:ctc_len1]\n",
    "len(text1), len(ctc_tokens1), ctc_logprobs1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  1,  4,  8,  2,  1,  2,  5,  3,  2, 17,  1,  4,  3,  2, 10,  4,\n",
       "        2,  8,  1,  4,  6,  4,  2,  2,  5,  7,  3,  3, 13,  4,  8,  2,  2,\n",
       "        2, 10,  2,  1,  2,  7, 18,  4,  1,  9,  6,  4,  2,  1, 12,  6,  2,\n",
       "        8,  7,  4,  2,  4,  2,  3,  9,  6, 11,  5, 13, 29, 19,  3,  5, 39,\n",
       "        5,  6, 24, 17,  3])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PadProcesser:\n",
    "    def __init__(self, labels):\n",
    "        labels = labels + ['~']\n",
    "        self.blank_id = len(labels) - 1\n",
    "        self.space_id = labels.index(' ')\n",
    "        self.labels_map = dict([(i, labels[i]) for i in range(len(labels))])\n",
    "    \n",
    "    def bound_text(self, tokens):\n",
    "        return [self.space_id] + tokens + [self.space_id]\n",
    "    \n",
    "    def bound_ctc(self, tokens, logprobs):\n",
    "        tokens = [self.space_id, self.blank_id] + tokens + [self.blank_id, self.space_id]\n",
    "        \n",
    "        logprobs = np.lib.pad(logprobs, ((2, 2), (0, 0)), 'edge')\n",
    "\n",
    "        def swap(col, a, b):\n",
    "            logprobs[col][a], logprobs[col][b] = logprobs[col][b], logprobs[col][a]\n",
    "        \n",
    "        first_token, last_token = tokens[2], tokens[-3]\n",
    "        swap(0, first_token, self.space_id)\n",
    "        swap(1, first_token, self.blank_id)\n",
    "        swap(-1, last_token, self.space_id)\n",
    "        swap(-2, last_token, self.blank_id)\n",
    "\n",
    "        return tokens, logprobs\n",
    "    \n",
    "    def merge(self, tokens):\n",
    "        output_tokens = []\n",
    "        output_cnts = []\n",
    "        cnt = 0\n",
    "        for i in range(len(tokens)):\n",
    "            if i != 0 and (tokens[i - 1] != tokens[i]):\n",
    "                output_tokens.append(tokens[i - 1])\n",
    "                output_cnts.append(cnt)\n",
    "\n",
    "                cnt = 0\n",
    "\n",
    "            cnt += 1\n",
    "\n",
    "        output_tokens.append(tokens[-1])\n",
    "        output_cnts.append(cnt)\n",
    "        \n",
    "        assert sum(output_cnts) == len(tokens), f'SUM_CHECK {sum(output_cnts)} vs {len(tokens)}'\n",
    "\n",
    "        return output_tokens, output_cnts\n",
    "    \n",
    "    def merge_with_blanks(self, tokens, cnts, logprobs=None):\n",
    "        def choose_sep(l, r, a, b):\n",
    "            # `tokens[l] == a and tokens[r] == b`.\n",
    "            sum_a, sum_b = logprobs[l, a], logprobs[l + 1:r + 1, b].sum()\n",
    "            best_sum, best_sep = sum_a + sum_b, 0\n",
    "            for sep in range(1, r - l):\n",
    "                sum_a += logprobs[l + sep, a]\n",
    "                sum_b -= logprobs[l + sep, b]\n",
    "                if sum_a + sum_b > best_sum:\n",
    "                    best_sum, best_sep = sum_a + sum_b, sep\n",
    "\n",
    "            return best_sep\n",
    "        \n",
    "        output_tokens = []\n",
    "        output_durs = []\n",
    "        blank_cnt = 0\n",
    "        total_cnt = 0\n",
    "        for token, cnt in zip(tokens, cnts):\n",
    "            total_cnt += cnt\n",
    "            if token == self.blank_id:\n",
    "                blank_cnt += cnt\n",
    "                continue\n",
    "            \n",
    "            output_tokens.append(token)\n",
    "            \n",
    "            if logprobs is None:\n",
    "                # Half half.\n",
    "                left_cnt = blank_cnt // 2\n",
    "            else:\n",
    "                # Clever sep choice based on sum of log probs.\n",
    "                left_cnt = choose_sep(\n",
    "                    l=total_cnt - cnt - blank_cnt - 1,\n",
    "                    r=total_cnt - cnt,\n",
    "                    a=output_tokens[-1],\n",
    "                    b=token,\n",
    "                )\n",
    "            right_cnt = blank_cnt - left_cnt\n",
    "            blank_cnt = 0\n",
    "            \n",
    "            if left_cnt:\n",
    "                output_durs[-1] += left_cnt\n",
    "            output_durs.append(cnt + right_cnt)\n",
    "        \n",
    "        output_durs[-1] += blank_cnt\n",
    "\n",
    "        assert sum(output_durs) == sum(cnts), f'SUM_CHECK {sum(output_durs)} vs {sum(cnts)}'\n",
    "\n",
    "        return output_tokens, output_durs\n",
    "    \n",
    "    def align(self, output_tokens, gt_text):\n",
    "        def make_str(tokens):\n",
    "            return ''.join(self.labels_map[c] for c in tokens)\n",
    "        \n",
    "        s = make_str(output_tokens)\n",
    "        t = make_str(gt_text)\n",
    "        alignmet = pairwise2.align.globalxx(s, t, gap_char='%')[0]\n",
    "        sa, ta, *_ = alignmet\n",
    "        return sa, ta\n",
    "    \n",
    "    def generate(self, gt_text, alignment, durs):\n",
    "        output_tokens = []\n",
    "        output_cnts = []\n",
    "        si, ti = 0, 0\n",
    "#         print(len(durs))\n",
    "        assert len(alignment[0]) == len(alignment[1])\n",
    "        for sc, tc in zip(*alignment):\n",
    "#             print(si, sc, ti, tc)\n",
    "            if sc == '%' and tc == '%':\n",
    "                print('NO WAY')\n",
    "                continue\n",
    "            \n",
    "            if sc == '%':\n",
    "                output_tokens.append(self.blank_id)\n",
    "                output_cnts.append(durs[si])\n",
    "                si += 1\n",
    "            elif tc == '%':\n",
    "                output_tokens.append(gt_text[ti])\n",
    "                output_cnts.append(0)\n",
    "                ti += 1\n",
    "            else:\n",
    "                output_tokens.append(gt_text[ti])\n",
    "                output_cnts.append(durs[si])\n",
    "                si += 1\n",
    "                ti += 1\n",
    "\n",
    "        assert sum(output_cnts) == sum(durs)\n",
    "        \n",
    "        return output_tokens, output_cnts\n",
    "\n",
    "    def __call__(self, text, ctc_tokens, ctc_logprobs, mel_len):\n",
    "        # This adds +2 tokens.\n",
    "        text = self.bound_text(text)\n",
    "        # This add +4 tokens, 2 of them are blank.\n",
    "        ctc_tokens, ctc_logprobs = self.bound_ctc(ctc_tokens, ctc_logprobs)\n",
    "\n",
    "        ctc_tokens, ctc_cnts = self.merge(ctc_tokens)\n",
    "        ctc_tokens, ctc_durs = self.merge_with_blanks(ctc_tokens, ctc_cnts, ctc_logprobs)\n",
    "        \n",
    "        alignment = self.align(text, ctc_tokens)\n",
    "        tokens, cnts = self.generate(text, alignment, ctc_durs)\n",
    "        tokens, durs = self.merge_with_blanks(tokens, cnts)\n",
    "        assert tokens == text, 'EXACT_TOKENS_MATCH_CHECK'\n",
    "\n",
    "        def adjust(start, direction, value):\n",
    "            i = start\n",
    "            while value != 0:\n",
    "                dur = durs[i]\n",
    "                \n",
    "                if value < 0:\n",
    "                    durs[i] = dur - value\n",
    "                else:\n",
    "                    durs[i] = max(dur - value, 0)\n",
    "                \n",
    "                value -= dur - durs[i]\n",
    "                i += direction\n",
    "\n",
    "        adjust(0, 1, 4)\n",
    "        adjust(-1, -1, sum(durs) - mel_len)  # Including 4 suffix bound tokens.\n",
    "        assert durs[0] >= 0, f'{durs[0]}'\n",
    "        assert durs[-1] >= 0, f'{durs[-1]}'\n",
    "        \n",
    "        durs = np.array(durs, dtype=np.long)\n",
    "        assert durs.shape[0] == len(text), f'LEN_CHECK {durs.shape[0]} vs {len(text)}'\n",
    "        assert np.sum(durs) == mel_len, f'SUM_CHECK {np.sum(durs)} vs {mel_len}'\n",
    "\n",
    "        return durs\n",
    "\n",
    "processer = PadProcesser(labels)\n",
    "durs1 = processer(text1, ctc_tokens1, ctc_logprobs1, mel_len1)\n",
    "durs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq:\n",
    "    def __init__(self, tokens, cnts=None):\n",
    "        if cnts is None:\n",
    "            cnts = np.ones(len(tokens), dtype=np.long)\n",
    "\n",
    "        assert len(tokens) == len(cnts)\n",
    "        self.tokens = tokens\n",
    "        self.cnts = cnts\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return repr(list(zip(self.tokens, self.cnts)))\n",
    "    \n",
    "    @property\n",
    "    def total(self):\n",
    "        return sum(self.cnts)\n",
    "    \n",
    "    def merge(self):\n",
    "        output_tokens = []\n",
    "        output_cnts = []\n",
    "        \n",
    "        cnt = 0\n",
    "        for i in range(len(self.tokens)):\n",
    "            if i != 0 and (self.tokens[i - 1] != self.tokens[i]):\n",
    "                output_tokens.append(self.tokens[i - 1])\n",
    "                output_cnts.append(cnt)\n",
    "\n",
    "                cnt = 0\n",
    "\n",
    "            cnt += self.cnts[i]\n",
    "\n",
    "        output_tokens.append(self.tokens[-1])\n",
    "        output_cnts.append(cnt)\n",
    "        \n",
    "        assert sum(output_cnts) == sum(self.cnts), \\\n",
    "            f'SUM-CHECK {sum(output_cnts)} vs {sum(self.cnts)}'\n",
    "\n",
    "        return Seq(output_tokens, output_cnts)\n",
    "    \n",
    "    def full_pad(self, blank_id, blank_cnt=1):\n",
    "        output_tokens = [blank_id]\n",
    "        output_cnts = [blank_cnt]\n",
    "\n",
    "        for token, cnt in zip(self.tokens, self.cnts):\n",
    "            output_tokens.append(token)\n",
    "            output_cnts.append(cnt)\n",
    "            \n",
    "            output_tokens.append(blank_id)\n",
    "            output_cnts.append(blank_cnt)\n",
    "        \n",
    "        return Seq(output_tokens, output_cnts)\n",
    "    \n",
    "    def adjust_cnt(self, value, start=-1, direction='left'):\n",
    "        tokens, cnts = self.tokens, self.cnts.copy()\n",
    "        \n",
    "        i, di = start, -1 if direction == 'left' else 1\n",
    "        while value != 0:\n",
    "            cnt = cnts[i]\n",
    "\n",
    "            if value < 0:\n",
    "                cnts[i] = cnt - value\n",
    "            else:\n",
    "                cnts[i] = max(cnt - value, 0)\n",
    "\n",
    "            value -= cnt - cnts[i]\n",
    "            i += di\n",
    "        \n",
    "        return Seq(tokens, cnts)\n",
    "    \n",
    "    def split2(self):\n",
    "        tokens1, cnts1 = [], []\n",
    "        tokens2, cnts2 = [], []\n",
    "        turn = 1\n",
    "        \n",
    "        for token, cnt in zip(self.tokens, self.cnts):\n",
    "            if turn == 1:\n",
    "                tokens1.append(token)\n",
    "                cnts1.append(cnt)\n",
    "            else:\n",
    "                tokens2.append(token)\n",
    "                cnts2.append(cnt)\n",
    "            \n",
    "            turn = 1 if turn == 2 else 2\n",
    "        \n",
    "        return Seq(tokens1, cnts1), Seq(tokens2, cnts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 5,  3,  6,  1,  0,  0,  3,  2,  1, 15,  0,  2,  3,  0,  8,  1,  1,\n",
       "         4,  2,  2,  5,  3,  0,  1,  4,  5,  2,  1, 12,  3,  2,  5,  1,  0,\n",
       "         8,  1,  0,  1,  4, 15,  4,  3,  8,  4,  2,  0,  0, 11,  2,  3,  0,\n",
       "        11,  3,  0,  0,  3,  0,  5, 13,  6,  2, 14,  0, 43,  4,  2, 40,  4,\n",
       "         2,  5, 37,  1]),\n",
       " array([1, 1, 2, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 2, 2, 3, 1, 2, 1, 1, 2, 1,\n",
       "        2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n",
       "        2, 2, 1, 1, 1, 2, 2, 2, 1, 2, 1, 2, 3, 1, 0, 1, 1, 1, 2, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1]))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FullProcessor(PadProcesser):\n",
    "    def __call__(self, text, ctc_tokens, ctc_logprobs, mel_len):\n",
    "        text = Seq(text).full_pad(self.blank_id)\n",
    "        ctc = Seq(ctc_tokens).merge().full_pad(self.blank_id, blank_cnt=0).merge()\n",
    "        \n",
    "        alignment = self.align(text.tokens, ctc.tokens)\n",
    "        gen = Seq(*self.generate(text.tokens, alignment, ctc.cnts)).merge()\n",
    "#         gen = gen.merge().adjust_cnt(gen.total - mel_len)\n",
    "        \n",
    "        # Two durs conditions.\n",
    "        assert gen.tokens == text.tokens\n",
    "        assert gen.total == mel_len\n",
    "        \n",
    "        blanks, text = gen.split2()\n",
    "        blanks = np.array(blanks.cnts, dtype=np.long)\n",
    "        cnts = np.array(text.cnts, dtype=np.long)\n",
    "        \n",
    "        assert len(blanks) == len(cnts) + 1\n",
    "        \n",
    "        return blanks, cnts\n",
    "\n",
    "\n",
    "processer = FullProcessor(labels)\n",
    "durs1 = processer(text1, ctc_tokens1, ctc_logprobs1, mel_len1)\n",
    "durs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT:  a s _ t h e _ i n s p e c t o r s _ o f _ p r i s o n s _ f o u n d _ t h e m _ i n _ e i g h t e e n _ t h i r t y - f i v e _ t o _ s i x .\n",
      "CTC:  ~ a ~ s ~ _ ~ t h e ~ _ ~ i ~ n ~ s p ~ e ~ c t ~ o ~ r ~ s ~ _ ~ o ~ f ~ _ ~ p r ~ i ~ s ~ o ~ n ~ s ~ _ ~ f ~ o ~ u ~ n d ~ _ ~ t h ~ e ~ m ~ _ ~ i ~ n ~ _ ~ e ~ i g h ~ t ~ e ~ e n ~ _ ~ t h i ~ r t ~ y ~ _ ~ f ~ i ~ v e ~ _ ~ t ~ o ~ _ ~ s ~ i ~ x ~ . ~\n"
     ]
    }
   ],
   "source": [
    "ctc_labels = ['_'] + labels[1:] + ['~']\n",
    "print('GT: ', *(ctc_labels[c] for c in text1))\n",
    "print('CTC: ', *(ctc_labels[c] for c, _ in itertools.groupby(ctc_tokens1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "944.1908576488495"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = lambda: processer(text1, ctc_tokens1, ctc_logprobs1, mel_len1)\n",
    "n, m = 10000, 280000\n",
    "(timeit.timeit(f, number=n) / n) * m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n"
     ]
    }
   ],
   "source": [
    "# NOTE: This is going pretty fast.\n",
    "durs_dir = pathlib.Path('/home/stanislavv/data/librimeta/durs/ljspeech_300epochs-qn15x5-eqlen')\n",
    "name = f'ljspeech_eval'\n",
    "durs_dir.mkdir(exist_ok=True)\n",
    "# k = -1\n",
    "\n",
    "durs = []\n",
    "for batch in tqdm.tqdm(zip(*evaluated_tensors), total=len(data_layer) // 64):\n",
    "    text = batch[2].numpy()\n",
    "    text_len = batch[3].numpy()\n",
    "    ctc_tokens = batch[1].numpy()\n",
    "    ctc_logprobs = batch[0].numpy()\n",
    "    ctc_len = batch[4].numpy()\n",
    "    mel_len = batch[-1].numpy()\n",
    "\n",
    "    for text1, text_len1, ctc_tokens1, ctc_logprobs1, ctc_len1, mel_len1 in zip(\n",
    "        text, text_len, ctc_tokens, ctc_logprobs, ctc_len, mel_len\n",
    "    ):\n",
    "        text1 = list(text1[:text_len1])\n",
    "        ctc_tokens1 = list(ctc_tokens1[:ctc_len1])\n",
    "        ctc_logprobs1 = ctc_logprobs1[:ctc_len1]\n",
    "        mel_len1 = mel_len1.item()\n",
    "        \n",
    "        assert mel_len1 == ctc_len1\n",
    "\n",
    "        durs1 = processer(text1, ctc_tokens1, ctc_logprobs1, mel_len1)\n",
    "        \n",
    "        durs.append(durs1)\n",
    "\n",
    "\n",
    "np.save(durs_dir / f'{name}.npy', durs, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  14,   15,   16,   17,   18,   19,   20,   21,   22,   23,   24,\n",
       "         25,   26,   27,   28,   29,   30,   31,   32,   33,   34,   35,\n",
       "         36,   37,   38,   39,   40,   41,   42,   43,   44,   45,   46,\n",
       "         47,   48,   49,   50,   51,   52,   53,   54,   55,   56,   57,\n",
       "         58,   59,   60,   61,   62,   63,   64,   65,   66,   67,   68,\n",
       "         69,   70,   71,   72,   73,   74,   75,   76,   77,   78,   79,\n",
       "         80,   81,   82,   83,   84,   85,   86,   87,   88,   89,   90,\n",
       "         91,   92,   93,   94,   95,   96,   97,   98,   99,  100,  101,\n",
       "        102,  103,  104,  105,  106,  107,  108,  109,  110,  111,  112,\n",
       "        113,  114,  116,  117,  118,  120,  122,  124,  126,  128,  130,\n",
       "        131,  132,  134,  136,  138,  140,  142,  144,  146,  148,  150,\n",
       "        152,  154,  156,  158,  160,  162,  164,  166,  168,  170,  172,\n",
       "        174,  176,  178,  180,  182,  184,  186,  188,  190,  192,  194,\n",
       "        196,  198,  200,  202,  204,  206,  208,  210,  212,  214,  216,\n",
       "        218,  220,  222,  224,  226,  228,  230,  232,  234,  236,  238,\n",
       "        240,  242,  244,  246,  248,  250,  252,  254,  256,  258,  260,\n",
       "        262,  264,  266,  268,  270,  272,  274,  276,  278,  280,  282,\n",
       "        284,  286,  288,  290,  292,  294,  296,  298,  300,  302,  304,\n",
       "        306,  308,  310,  312,  314,  316,  318,  320,  322,  324,  326,\n",
       "        328,  330,  332,  334,  336,  338,  340,  342,  344,  346,  348,\n",
       "        350,  352,  354,  356,  358,  360,  362,  364,  366,  368,  370,\n",
       "        372,  374,  376,  378,  380,  382,  384,  386,  388,  390,  392,\n",
       "        394,  396,  398,  400,  402,  404,  406,  408,  410,  412,  414,\n",
       "        416,  418,  420,  422,  424,  426,  428,  430,  432,  436,  438,\n",
       "        440,  442,  446,  448,  452,  454,  456,  458,  460,  462,  464,\n",
       "        466,  470,  472,  474,  476,  482,  484,  488,  490,  492,  494,\n",
       "        502,  508,  510,  512,  514,  518,  522,  524,  526,  534,  538,\n",
       "        540,  554,  558,  568,  586,  590,  592,  602,  630,  644,  652,\n",
       "        666,  670,  676,  684,  760,  816,  840, 1130])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(max_blanks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1130"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(b.max() for b, _ in durs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(d.max() for _, d in durs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1167549, 49408497, 2.363053059476794)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num, total = 0, 0\n",
    "for b, _ in durs:\n",
    "    num += (b > 30).sum()\n",
    "    total += len(b)\n",
    "\n",
    "num, total, (num / total * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31619, 49129870, 0.06435799646935765)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num, total = 0, 0\n",
    "for _, d in durs:\n",
    "    num += (d > 15).sum()\n",
    "    total += len(d)\n",
    "\n",
    "num, total, (num / total * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/278627 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 14127/278627 [00:00<00:01, 141258.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 26700/278627 [00:00<00:01, 136209.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 36747/278627 [00:00<00:01, 123074.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 49495/278627 [00:00<00:01, 124361.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 62138/278627 [00:00<00:01, 124971.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 74744/278627 [00:00<00:01, 125295.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███▏      | 87506/278627 [00:00<00:01, 125982.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 100505/278627 [00:00<00:01, 127157.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 113237/278627 [00:00<00:01, 127205.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 125793/278627 [00:01<00:01, 126704.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 138547/278627 [00:01<00:01, 126951.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 151085/278627 [00:01<00:01, 126474.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 163550/278627 [00:01<00:00, 125234.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 175949/278627 [00:01<00:00, 123761.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 188242/278627 [00:01<00:00, 122351.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 200423/278627 [00:01<00:00, 121550.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▋  | 212541/278627 [00:01<00:00, 120701.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 224767/278627 [00:01<00:00, 121163.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 237060/278627 [00:01<00:00, 121684.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|████████▉ | 249378/278627 [00:02<00:00, 122127.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 261584/278627 [00:02<00:00, 121933.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 278627/278627 [00:02<00:00, 123477.48it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEDCAYAAAAlRP8qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAO+0lEQVR4nO3dfaxkdX3H8fenLNpEjWD3RilQrw/EpjZV6AbRWkNqtTwYtg+2XWIEBbOxhVaTNs1aEzT+hW1qEx8q2eoGMQaJ+NBtWYu0mmCTQrmQBXlQWewalqxwFQWNTe3ab/+Yc+307syduXvnzsz++n4lk3sefmfON78987nn/s6Zs6kqJEnHv5+adQGSpMkw0CWpEQa6JDXCQJekRhjoktQIA12SGjHTQE+yJ8ljSe4do+1fJ9nfvb6e5HvTqFGSjheZ5X3oSV4F/AC4rqp+cR3b/RFwZlVdtmnFSdJxZqZn6FV1K/B4/7IkL0jyj0nuTPLlJD8/YNOLgeunUqQkHSe2zLqAAXYDb62qB5O8DPgb4NdWViZ5LvA84Iszqk+S5tJcBXqSpwOvAD6VZGXxU1c12wHcWFU/nmZtkjTv5irQ6Q0Bfa+qXrpGmx3AFVOqR5KOG3N122JVPQn8e5LfBUjPS1bWd+PpJwP/OqMSJWluzfq2xevphfOLkhxKcjnwBuDyJHcD9wHb+zbZAXyyfESkJB1lprctSpImZ66GXCRJx25mF0W3bt1ai4uLs9q9JB2X7rzzzm9X1cKgdTML9MXFRZaWlma1e0k6LiX55rB1DrlIUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1Ij5u156GNZ3HXThrY/ePWFE6pEkuaHZ+iS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREjAz3J6Um+lOT+JPcleduANkny/iQHktyT5KzNKVeSNMw4z0M/AvxJVd2V5BnAnUluqar7+9qcD5zRvV4GfLj7KUmakpFn6FV1uKru6qa/DzwAnLqq2Xbguuq5DTgpySkTr1aSNNS6xtCTLAJnArevWnUq8HDf/CGODn2S7EyylGRpeXl5fZVKktY0dqAneTrwaeDtVfXkseysqnZX1baq2rawsHAsbyFJGmKsQE9yIr0w/0RVfWZAk0eA0/vmT+uWSZKmZJy7XAJ8FHigqt43pNle4JLubpdzgCeq6vAE65QkjTDOXS6/ArwR+EqS/d2yPwd+DqCqrgH2ARcAB4AfAm+efKmSpLWMDPSq+hcgI9oUcMWkipIkrZ/fFJWkRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjRgZ6En2JHksyb1D1p+b5Ikk+7vXVZMvU5I0ypYx2lwLfBC4bo02X66q102kIknSMRl5hl5VtwKPT6EWSdIGTGoM/eVJ7k7y+SQvHtYoyc4kS0mWlpeXJ7RrSRJMJtDvAp5bVS8BPgB8bljDqtpdVduqatvCwsIEdi1JWrHhQK+qJ6vqB930PuDEJFs3XJkkaV02HOhJnpMk3fTZ3Xt+Z6PvK0lan5F3uSS5HjgX2JrkEPAu4ESAqroGeD3wB0mOAP8B7Kiq2rSKJUkDjQz0qrp4xPoP0rutUZI0Q35TVJIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqRFbZl3A8Whx100b2v7g1RdOqBJJ+l8jz9CT7EnyWJJ7h6xPkvcnOZDkniRnTb5MSdIo4wy5XAuct8b684EzutdO4MMbL0uStF4jA72qbgUeX6PJduC66rkNOCnJKZMqUJI0nklcFD0VeLhv/lC3TJI0RVO9yyXJziRLSZaWl5enuWtJat4kAv0R4PS++dO6ZUepqt1Vta2qti0sLExg15KkFZMI9L3AJd3dLucAT1TV4Qm8ryRpHUbeh57keuBcYGuSQ8C7gBMBquoaYB9wAXAA+CHw5s0qVpI03MhAr6qLR6wv4IqJVSRJOiZ+9V+SGmGgS1IjDHRJaoSBLkmN8GmLx6GNPu0RfOKj1CLP0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1YqxAT3Jekq8lOZBk14D1b0qynGR/93rL5EuVJK1ly6gGSU4APgS8BjgE3JFkb1Xdv6rpDVV15SbUKEkawzhn6GcDB6rqG1X1I+CTwPbNLUuStF7jBPqpwMN984e6Zav9TpJ7ktyY5PRBb5RkZ5KlJEvLy8vHUK4kaZhJXRT9e2Cxqn4JuAX42KBGVbW7qrZV1baFhYUJ7VqSBOMF+iNA/xn3ad2yn6iq71TVf3azHwF+eTLlSZLGNU6g3wGckeR5SZ4C7AD29jdIckrf7EXAA5MrUZI0jpF3uVTVkSRXAjcDJwB7quq+JO8BlqpqL/DHSS4CjgCPA2/axJolSQOMDHSAqtoH7Fu17Kq+6XcA75hsaZKk9fCbopLUiLHO0KXVFnfdtKHtD1594YQqkbTCM3RJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqRFbZl2AdCwWd920oe0PXn3hhCqR5odn6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakR3rYoHQNvm9Q88gxdkhoxVqAnOS/J15IcSLJrwPqnJrmhW397ksVJFypJWtvIIZckJwAfAl4DHALuSLK3qu7va3Y58N2qemGSHcB7gd/fjIIlOeSjwcYZQz8bOFBV3wBI8klgO9Af6NuBd3fTNwIfTJKqqgnWKmlOzPoXyv/3/Q+TUZmb5PXAeVX1lm7+jcDLqurKvjb3dm0OdfMPdW2+veq9dgI7u9kXAV87xrq3At8e2Wp25r0+mP8arW9jrG9j5rm+51bVwqAVU73Lpap2A7s3+j5Jlqpq2wRK2hTzXh/Mf43WtzHWtzHzXt8w41wUfQQ4vW/+tG7ZwDZJtgDPBL4ziQIlSeMZJ9DvAM5I8rwkTwF2AHtXtdkLXNpNvx74ouPnkjRdI4dcqupIkiuBm4ETgD1VdV+S9wBLVbUX+Cjw8SQHgMfphf5m2vCwzSab9/pg/mu0vo2xvo2Z9/oGGnlRVJJ0fPCbopLUCANdkhox14E+z48cSHJ6ki8luT/JfUneNqDNuUmeSLK/e101rfq6/R9M8pVu30sD1ifJ+7v+uyfJWVOs7UV9/bI/yZNJ3r6qzdT7L8meJI91361YWfasJLckebD7efKQbS/t2jyY5NJBbTapvr9M8tXu3/CzSU4asu2ax8Mm1vfuJI/0/TteMGTbNT/vm1jfDX21HUyyf8i2m95/G1ZVc/midwH2IeD5wFOAu4FfWNXmD4FruukdwA1TrO8U4Kxu+hnA1wfUdy7wDzPsw4PA1jXWXwB8HghwDnD7DP+tv0XvCxMz7T/gVcBZwL19y/4C2NVN7wLeO2C7ZwHf6H6e3E2fPKX6Xgts6abfO6i+cY6HTazv3cCfjnEMrPl536z6Vq3/K+CqWfXfRl/zfIb+k0cOVNWPgJVHDvTbDnysm74ReHWSTKO4qjpcVXd1098HHgBOnca+J2g7cF313AaclOSUGdTxauChqvrmDPb9f1TVrfTu1OrXf5x9DPjNAZv+BnBLVT1eVd8FbgHOm0Z9VfWFqjrSzd5G77siMzGk/8Yxzud9w9aqr8uO3wOun/R+p2WeA/1U4OG++UMcHZg/adMd0E8APzOV6vp0Qz1nArcPWP3yJHcn+XySF0+1MCjgC0nu7B67sNo4fTwNOxj+IZpl/614dlUd7qa/BTx7QJt56cvL6P3VNcio42EzXdkNCe0ZMmQ1D/33q8CjVfXgkPWz7L+xzHOgHxeSPB34NPD2qnpy1eq76A0jvAT4APC5KZf3yqo6CzgfuCLJq6a8/5G6L6tdBHxqwOpZ999Rqve391ze65vkncAR4BNDmszqePgw8ALgpcBhesMa8+hi1j47n/vP0zwH+tw/ciDJifTC/BNV9ZnV66vqyar6QTe9DzgxydZp1VdVj3Q/HwM+S+/P2n7j9PFmOx+4q6oeXb1i1v3X59GVoaju52MD2sy0L5O8CXgd8Ibul85RxjgeNkVVPVpVP66q/wb+dsh+Z91/W4DfBm4Y1mZW/bce8xzoc/3IgW687aPAA1X1viFtnrMypp/kbHr9PZVfOEmeluQZK9P0Lpzdu6rZXuCS7m6Xc4An+oYWpmXoWdEs+2+V/uPsUuDvBrS5GXhtkpO7IYXXdss2XZLzgD8DLqqqHw5pM87xsFn19V+X+a0h+x3n876Zfh34anVPjF1tlv23LrO+KrvWi95dGF+nd/X7nd2y99A7cAF+mt6f6geAfwOeP8XaXknvT+97gP3d6wLgrcBbuzZXAvfRu2J/G/CKKdb3/G6/d3c1rPRff32h95+XPAR8Bdg25X/fp9EL6Gf2LZtp/9H75XIY+C9647iX07su88/Ag8A/Ac/q2m4DPtK37WXdsXgAePMU6ztAb/x55ThcufPrZ4F9ax0PU6rv493xdQ+9kD5ldX3d/FGf92nU1y2/duW462s79f7b6Muv/ktSI+Z5yEWStA4GuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWrE/wCkPqnn0MgmOwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(\n",
    "    list(itertools.chain.from_iterable(b for b, _ in tqdm.tqdm(durs))),\n",
    "    bins=range(20),\n",
    ");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
